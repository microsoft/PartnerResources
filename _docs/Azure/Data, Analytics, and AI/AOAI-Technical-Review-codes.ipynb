{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Code examples for working with Azure Open AI"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\r\n",
        "The examples below use Python 3. Environment variables are stored in a `.env` file and loaded using `dotenv` package. You can load them with your method of choice.\r\n",
        "\r\n",
        "Here is an example of a `.env` file. (Note: sometimes file starting with `.` are hidden and can't be seen by your OS file browser.)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\r\n",
        "OPENAI_ENDPOINT=https://<your deployment name>.openai.azure.com/\r\n",
        "OPENAI_API_KEY=<your key>\r\n",
        "OPENAI_DEPLOYMENTID=<name (id) of your OpenAI model deployment for completion>\r\n",
        "OPENAI_EMBEDDING_DEPLOYMENTID=<name (id) of your OpenAI model deployment for word embedding>\r\n",
        "# below variables are needed if you'd like to run cognitive svc translator\r\n",
        "# create a translator resource under cognitive services\r\n",
        "AZURE_COGNITIVE_SVC_TEXT_ENDPOINT=https://api.cognitive.microsofttranslator.com/ \r\n",
        "AZURE_COGNITIVE_SVC_DOC_ENDPOINT=https://<your deployment name>.cognitiveservices.azure.com/\r\n",
        "AZURE_COGNITIVE_SVC_API_KEY=<your cog svc key>\r\n",
        "AZURE_COGNITIVE_SVC_REGION=<your resource region>"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following packages were installed to run the sample codes.\r\n",
        "- `dotenv` to load `.env` file\r\n",
        "- `openai` for python SDK examples"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Example 1: Sentiment analysis (Rest API) \n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load environment variables contaning endpoint and API key\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import os \n",
        "\n",
        "\n",
        "openai_endpoint = os.getenv('OPENAI_ENDPOINT')\n",
        "openai_key = os.getenv('OPENAI_API_KEY')\n",
        "deployment_id = os.getenv('OPENAI_DEPLOYMENTID')\n",
        "api_version = \"2022-12-01\"\n",
        "\n",
        "fastfood_reviews = [\n",
        "    \"I went in with a large order. Maurice was cool, and made sure that everything was perfect.  This was my first time at this location, and I really don't expect good customer service from McDonald's.  Glad to see that this location is better then most.\",\n",
        "    \"It took us 35 minutes to get through the drive thru. There were a lot of cars behind us and in front of us. The staff inside were just nonchalant walking around like it's a easy simple day. Then they got our order wrong. I wasn't about to wait another 35 minutes.\",\n",
        "    \"Very slow line, they must have been short staffed. And the electronics went down so I could not order with points or coupons online in advance. Big Macs are always good though. The fries were very good.\",\n",
        "]\n",
        "\n",
        "question = 'what is the sentiment of each of the reviews: Give the response in one line'\n",
        "\n",
        "prompt = question+'\\n'\n",
        "for i,review in enumerate(fastfood_reviews):\n",
        "    prompt += f'{i+1}. {review}\\n'\n",
        "\n",
        "\n",
        "payload = {\n",
        "    # The prompt(s) to generate completions for, encoded as a string, a list of strings, or a list of token lists. Note that <\\|endoftext\\|> is the document separator that the model sees during training, so if a prompt isn't specified the model will generate as if from the beginning of a new document.\n",
        "    \"prompt\":prompt,\n",
        "    \n",
        "    # The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens can't exceed the model's context length. Most models have a context length of 2048 tokens (except davinci-codex, which supports 4096).\n",
        "    \"max_tokens\": 1000,\n",
        "    \n",
        "    # What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer. We generally recommend altering this or top_p but not both.\n",
        "    \"temperature\":0.5,\n",
        "    \n",
        "    # for a list of all available parameters, visit:\n",
        "    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#completions\n",
        "}\n",
        "\n",
        "response = requests.post(\n",
        "    f\"{openai_endpoint}/openai/deployments/{deployment_id}/completions?api-version={api_version}\", \n",
        "    json.dumps(payload), \n",
        "    headers={\"api-key\": openai_key}\n",
        ").json()\n",
        "\n",
        "print(f'''Here is the response of the above code: {response['choices'][0]['text']}''')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1676319605390
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Example 2: Text summarization (Python SDK - Completion)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load environment variables contaning endpoint and API key\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import openai\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = os.getenv('OPENAI_ENDPOINT')\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "deployment_id = os.getenv('OPENAI_DEPLOYMENTID')\n",
        "openai.api_version = \"2022-12-01\"\n",
        "\n",
        "prompt = \"Summerize the following document:\\n\"\n",
        "# sample.txt contains 3 paragraphs about Giraffes from wikipedia\n",
        "with open('sample.txt') as f:\n",
        "  prompt += f.read()\n",
        "\n",
        "# print(prompt)\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=deployment_id,\n",
        "  prompt=prompt,\n",
        "  temperature=0.7,\n",
        "  max_tokens=200,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  best_of=1,\n",
        "  stop=None)\n",
        "\n",
        "print(f''' Here is the result of the above code: {response.choices[0].text}''')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1676319716542
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Example 3: Word embedding (Python SDK - Embedding)\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# load environment variables contaning endpoint and API key\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import openai\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = os.getenv('OPENAI_ENDPOINT')\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "deployment_id = os.getenv('OPENAI_EMBEDDING_DEPLOYMENTID')\n",
        "openai.api_version = \"2022-12-01\"\n",
        "\n",
        "def getEmbedding(input: str):\n",
        "    response = openai.Embedding.create(\n",
        "        engine=deployment_id,\n",
        "        input=input,\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "\n",
        "inputs = [\n",
        "    \"coffee\", \"tea\", \"sugar\",\"milk\",\"breakfast\",\"cream\", \"chamomile\",\"green tea\",\n",
        "    \"laptop\", \"cpu\", \"monitor\", \"memory\",\"storage\", \"keyboard\",\"mouse\", \"headphone\",\n",
        "]\n",
        "embeddings = [getEmbedding(x) for x in inputs]\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1676319798669
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np \n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "embeddings_vec = np.array(embeddings)\n",
        "\n",
        "reduced_vec = PCA(random_state=0).fit_transform(embeddings_vec)[:,:3]\n",
        "\n",
        "all = [reduced_vec[:8],\n",
        "       reduced_vec[8:16],\n",
        "]\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot()\n",
        "ax.set_xlim([-1,1])\n",
        "ax.set_ylim([-1,1])\n",
        "# for p in reduced_vec :\n",
        "for v in all:\n",
        "    xs = [p[0] for p in v]\n",
        "    ys = [p[1] for p in v]\n",
        "    zs = [p[2] for p in v]\n",
        "    ax.scatter(xs, ys, marker='o')\n",
        "\n",
        "print(\"Below is the resulting plot of the above code: \")\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1676319827015
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Example 4: Few-shot learning (Rest API)  "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load environment variables contaning endpoint and API key\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import os \n",
        "\n",
        "openai_endpoint = os.getenv('OPENAI_ENDPOINT')\n",
        "openai_key = os.getenv('OPENAI_API_KEY')\n",
        "deployment_id = os.getenv('OPENAI_DEPLOYMENTID')\n",
        "api_version = \"2022-12-01\"\n",
        "\n",
        "\n",
        "prompt = '''Q: how do you draw a car with shapes?\n",
        "'''\n",
        "\n",
        "payload = {\"prompt\":prompt,\"max_tokens\": 1000,\"temperature\":0.5,}\n",
        "\n",
        "response = requests.post(\n",
        "    f\"{openai_endpoint}/openai/deployments/{deployment_id}/completions?api-version={api_version}\", \n",
        "    json.dumps(payload), \n",
        "    headers={\"api-key\": openai_key}\n",
        ").json()\n",
        "\n",
        "print(f'''{response['choices'][0]['text']}''')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1676320968458
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load environment variables contaning endpoint and API key\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import os \n",
        "\n",
        "openai_endpoint = os.getenv('OPENAI_ENDPOINT')\n",
        "openai_key = os.getenv('OPENAI_API_KEY')\n",
        "deployment_id = os.getenv('OPENAI_DEPLOYMENTID')\n",
        "api_version = \"2022-12-01\"\n",
        "\n",
        "\n",
        "prompt = '''\n",
        "Q: how do you draw a house with shapes?\n",
        "A: by drawing a triabgle on top of a square.\n",
        "\n",
        "Q: how do you draw a star with shapes?\n",
        "A: by drawing 5 triangles on edges of a pentagon.\n",
        "\n",
        "Q: how do you draw a car with shapes?\n",
        "'''\n",
        "\n",
        "payload = {\"prompt\":prompt,\"max_tokens\": 1000,\"temperature\":0.5,}\n",
        "\n",
        "response = requests.post(\n",
        "    f\"{openai_endpoint}/openai/deployments/{deployment_id}/completions?api-version={api_version}\", \n",
        "    json.dumps(payload), \n",
        "    headers={\"api-key\": openai_key}\n",
        ").json()\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Pricing\n",
        "Azure Open AI usage is charged based on token consumption. You will be charged for both tokens sent and received.\n",
        "The following table is current as of February 2023.\n",
        "\n",
        "|Series      | Model | Inferencing cost per 1000 tokens\n",
        "|------------|------|---------\n",
        "|Base        |Ada    | $0.0004\n",
        "|Base        |Babbage| $0.0005\n",
        "|Base        |Curie  | $0.002\n",
        "|Base        |Davinci| $0.02\n",
        "|Codex       |Code-Cushman | $0.024\n",
        "|Codex       |Code-Davinci | $0.10\n",
        "|Embedding   | Ada   | $0.004\n",
        "|Embedding   |Babbage| $0.005\n",
        "|Embedding   |Curie  | $0.02\n",
        "|Embedding   |Davinci| $0.20\n",
        "\n",
        "\n",
        "## Example 5: Cost estimation (Python SDK - Completion)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# load environment variables contaning endpoint and API key\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import openai\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = os.getenv('OPENAI_ENDPOINT')\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "deployment_id = os.getenv('OPENAI_DEPLOYMENTID')\n",
        "openai.api_version = \"2022-12-01\"\n",
        "\n",
        "unit_cost={\n",
        "  \"completion\":{\"ada\":0.0004, \"babbage\":0.0005, \"curie\":0.002, \"davinci\":0.02},\n",
        "  \"embedding\" :{\"ada\":0.0040, \"babbage\":0.0050, \"curie\":0.020, \"davinci\":0.20}\n",
        "}\n",
        "\n",
        "prompt = \"Summerize the following article:\\n\"\n",
        "with open('few-shot.txt') as f:\n",
        "  prompt += f.read()\n",
        "\n",
        "# print(prompt)\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=deployment_id,\n",
        "  prompt=prompt,\n",
        "  temperature=0.7,\n",
        "  max_tokens=2000,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  best_of=1,\n",
        "  stop=None)\n",
        "\n",
        "token_cost = unit_cost['completion']['davinci']\n",
        "\n",
        "print(f\"\"\"Response: \n",
        "{response['choices'][0]['text']}\n",
        "--------------------------\n",
        "Usage:\n",
        "  - Prompt tokens:     {response['usage']['prompt_tokens']}\n",
        "  - Completion tokens: {response['usage']['completion_tokens']}\n",
        "  - Total tokens:      {response['usage']['total_tokens']}\n",
        "Estimated cost:\n",
        "  {response['usage']['total_tokens']} tok x {token_cost} ($/1000 tok) = ${response['usage']['total_tokens']*token_cost*0.0001:.4f}\n",
        "\"\"\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1676764769068
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 6: Translation \r\n",
        "### 6.1. OpenAI Python SDK"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load environment variables contaning endpoint and API key\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import openai\n",
        "import os\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = os.getenv('OPENAI_ENDPOINT')\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "deployment_id = os.getenv('OPENAI_DEPLOYMENTID')\n",
        "openai.api_version = \"2022-12-01\"\n",
        "\n",
        "prompt = \"Translate this to Farsi:\\n I would really like to drive your car around the block a few times!\"\n",
        "\n",
        "\n",
        "# print(prompt)\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=deployment_id,\n",
        "  prompt=prompt,\n",
        "  temperature=0.7,\n",
        "  max_tokens=2000,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  best_of=1,\n",
        "  stop=None)\n",
        "\n",
        "print(response.choices[0].text)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2. Cognitive Services - Translator (Rest API)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load environment variables contaning endpoint and API key\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import os, uuid, requests\n",
        "endpoint = os.getenv('AZURE_COGNITIVE_SVC_TEXT_ENDPOINT')\n",
        "api_key = os.getenv('AZURE_COGNITIVE_SVC_API_KEY')\n",
        "location = os.getenv('AZURE_COGNITIVE_SVC_REGION')\n",
        "\n",
        "params = {\n",
        "    'api-version': '3.0',\n",
        "    'from': 'en',\n",
        "    'to': ['fa']\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    'Ocp-Apim-Subscription-Key': api_key,\n",
        "    # location required if you're using a multi-service or regional (not global) resource.\n",
        "    'Ocp-Apim-Subscription-Region': location,\n",
        "    'Content-type': 'application/json',\n",
        "    'X-ClientTraceId': str(uuid.uuid4())\n",
        "}\n",
        "\n",
        "# You can pass more than one object in body.\n",
        "body = [{\n",
        "    'text': 'I would really like to drive your car around the block a few times!'\n",
        "}]\n",
        "\n",
        "request = requests.post(f'{endpoint}translate', params=params, headers=headers, json=body)\n",
        "response = request.json()\n",
        "\n",
        "print(json.dumps(response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}